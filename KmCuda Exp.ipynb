{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libKMCUDA import kmeans_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADED\n",
      "[[0.66424388 0.56606836 0.50727742 ... 0.62679593 0.61127706 0.54882931]\n",
      " [0.63996439 0.73253994 0.56657055 ... 0.5691039  0.5696665  0.63104607]\n",
      " [0.69608707 0.74612231 0.53833612 ... 0.50491309 0.54635844 0.65518444]\n",
      " ...\n",
      " [0.66554482 0.70617891 0.5890896  ... 0.56739975 0.73123677 0.76174836]\n",
      " [0.65692766 0.73210897 0.50131871 ... 0.56785813 0.65907677 0.67341439]\n",
      " [0.67561254 0.72804485 0.56012496 ... 0.57527451 0.67883786 0.62172116]]\n",
      "DATASET NORMALIZED\n",
      "PCA FIT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "full_csv = \"/mnt/data/SCALABLE/HARRISON/pca/full.csv\"\n",
    "df = pd.read_csv(full_csv, sep=\",\", header=None, index_col=0)\n",
    "print(\"DATASET LOADED\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "data_rescaled = scaler.fit_transform(df)\n",
    "print(data_rescaled)\n",
    "print(\"DATASET NORMALIZED\")\n",
    "#Fitting the PCA algorithm with our Data\n",
    "pca_model = PCA(n_components=130).fit(data_rescaled)\n",
    "print(\"PCA FIT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pca_model, open('pca_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open('scaler.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_arr = pca_model.transform(data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.12432963e-01 -1.04179531e+00 -5.81344170e-01  8.25516843e-01\n",
      "  1.19773258e+00  5.42017534e-02 -4.01070751e-01 -4.81321118e-02\n",
      " -5.89404607e-01  7.81964206e-01 -4.98436574e-01  1.67939673e-01\n",
      " -1.76223754e+00  1.30231297e-01  3.22969089e-01 -4.45078744e-02\n",
      "  1.31161112e-01 -2.62203441e-01  4.17634282e-02 -3.75637576e-01\n",
      " -5.58989406e-01 -7.04312786e-01 -2.12056410e-02 -3.44439815e-01\n",
      "  2.02940733e-01 -2.76587065e-01  3.37578238e-01  7.31284432e-04\n",
      "  5.74775451e-02  2.59248560e-01  1.26137279e-01 -6.32594248e-02\n",
      "  9.88131131e-01 -3.69802418e-01  1.74607340e-01 -1.24009167e-01\n",
      "  4.02667404e-02 -4.15449033e-01  2.62635179e-01  2.23535329e-01\n",
      " -2.29182812e-01  6.24029815e-01  3.24639802e-02  2.39205723e-01\n",
      " -2.32283613e-01 -1.17474965e-01  1.47937884e-01  6.76836145e-02\n",
      " -8.82700357e-02  3.61094322e-01  3.56859047e-02  9.08291870e-02\n",
      "  4.04679493e-01 -1.76940784e-01 -1.59571078e-02 -3.90178770e-02\n",
      " -2.16748506e-02 -1.03200094e-01  1.41472432e-01 -2.35894206e-01\n",
      "  2.92014582e-01  2.31944293e-01  1.37624087e-01 -5.41145141e-04\n",
      "  7.28874272e-02 -4.46315893e-01 -1.20859282e-01  3.17788258e-02\n",
      " -1.13978037e-01 -6.07163801e-02 -2.75417280e-02  2.28983238e-02\n",
      "  3.15882307e-01  3.80606298e-01 -6.95844263e-04  1.90003432e-01\n",
      "  1.31599508e-01 -1.42514331e-01 -5.73531274e-02 -1.43862491e-01\n",
      "  2.14976756e-01 -9.15150413e-02  9.09874485e-03  2.23587149e-01\n",
      " -3.37879357e-01 -9.88718595e-02  1.91309246e-01 -8.41767781e-02\n",
      "  3.10077320e-01  6.25043308e-02 -2.43696023e-01 -2.29976535e-01\n",
      " -1.33463761e-01  1.01767023e-01 -3.61710734e-02 -2.10290882e-01\n",
      "  2.71731872e-01  4.98298805e-02 -5.86326119e-02  1.54087402e-01\n",
      " -1.52473240e-01  3.87868487e-02 -1.78926596e-02  1.12073181e-01\n",
      "  1.54596813e-01  3.54497535e-02  8.69412125e-02 -1.58121414e-01\n",
      "  1.48566810e-01 -1.88512912e-03 -2.73687850e-02  1.47098622e-02\n",
      " -5.23148911e-03  6.48886466e-02  2.98331090e-02 -7.92002043e-02\n",
      "  8.47352939e-02  3.77984126e-02  3.24852671e-02  2.34759029e-02\n",
      "  1.71104659e-01 -1.79466272e-02  2.23912920e-02 -1.54299755e-01\n",
      "  1.73412267e-01 -5.95961398e-02  1.48275543e-01 -4.60505148e-02\n",
      "  1.02557749e-01  6.72188444e-02]\n"
     ]
    }
   ],
   "source": [
    "print(pca_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pca_arr).to_csv(\"/mnt/data/SCALABLE/HARRISON/pca/pca_130_new.csv\", header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/data/SCALABLE/HARRISON/pca/pca_130_new.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = pd.read_csv(path, sep=\",\", header=None, index_col=None, dtype=\"float16\")\n",
    "arr = arr.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57381, 130)\n"
     ]
    }
   ],
   "source": [
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, assignments = kmeans_cuda(\n",
    "    arr, 169, metric=\"L2\", verbosity=1, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dizionario con come chiave il centroide e come valore la lista di punti corrispondenti.\n",
    "points_centroids_map = {x: [] for x in range(0,169)}\n",
    "for index, item in enumerate(assignments):\n",
    "    points_centroids_map[item].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(points_centroids_map, open('points_centroids_map.pickle', 'wb'))\n",
    "pickle.dump(centroids, open('centroids.pickle', 'wb'))\n",
    "pickle.dump(assignments, open('assignments.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 0\n",
      "V; 179\n",
      "K: 1\n",
      "V; 401\n",
      "K: 2\n",
      "V; 396\n",
      "K: 3\n",
      "V; 630\n",
      "K: 4\n",
      "V; 449\n",
      "K: 5\n",
      "V; 123\n",
      "K: 6\n",
      "V; 239\n",
      "K: 7\n",
      "V; 556\n",
      "K: 8\n",
      "V; 248\n",
      "K: 9\n",
      "V; 344\n",
      "K: 10\n",
      "V; 430\n",
      "K: 11\n",
      "V; 0\n",
      "K: 12\n",
      "V; 76\n",
      "K: 13\n",
      "V; 317\n",
      "K: 14\n",
      "V; 448\n",
      "K: 15\n",
      "V; 224\n",
      "K: 16\n",
      "V; 863\n",
      "K: 17\n",
      "V; 225\n",
      "K: 18\n",
      "V; 550\n",
      "K: 19\n",
      "V; 140\n",
      "K: 20\n",
      "V; 28\n",
      "K: 21\n",
      "V; 183\n",
      "K: 22\n",
      "V; 435\n",
      "K: 23\n",
      "V; 661\n",
      "K: 24\n",
      "V; 243\n",
      "K: 25\n",
      "V; 442\n",
      "K: 26\n",
      "V; 303\n",
      "K: 27\n",
      "V; 85\n",
      "K: 28\n",
      "V; 415\n",
      "K: 29\n",
      "V; 192\n",
      "K: 30\n",
      "V; 137\n",
      "K: 31\n",
      "V; 492\n",
      "K: 32\n",
      "V; 585\n",
      "K: 33\n",
      "V; 570\n",
      "K: 34\n",
      "V; 361\n",
      "K: 35\n",
      "V; 538\n",
      "K: 36\n",
      "V; 129\n",
      "K: 37\n",
      "V; 735\n",
      "K: 38\n",
      "V; 95\n",
      "K: 39\n",
      "V; 234\n",
      "K: 40\n",
      "V; 63\n",
      "K: 41\n",
      "V; 158\n",
      "K: 42\n",
      "V; 373\n",
      "K: 43\n",
      "V; 430\n",
      "K: 44\n",
      "V; 334\n",
      "K: 45\n",
      "V; 351\n",
      "K: 46\n",
      "V; 316\n",
      "K: 47\n",
      "V; 401\n",
      "K: 48\n",
      "V; 303\n",
      "K: 49\n",
      "V; 268\n",
      "K: 50\n",
      "V; 311\n",
      "K: 51\n",
      "V; 253\n",
      "K: 52\n",
      "V; 499\n",
      "K: 53\n",
      "V; 425\n",
      "K: 54\n",
      "V; 79\n",
      "K: 55\n",
      "V; 439\n",
      "K: 56\n",
      "V; 201\n",
      "K: 57\n",
      "V; 230\n",
      "K: 58\n",
      "V; 528\n",
      "K: 59\n",
      "V; 190\n",
      "K: 60\n",
      "V; 390\n",
      "K: 61\n",
      "V; 293\n",
      "K: 62\n",
      "V; 86\n",
      "K: 63\n",
      "V; 514\n",
      "K: 64\n",
      "V; 253\n",
      "K: 65\n",
      "V; 668\n",
      "K: 66\n",
      "V; 266\n",
      "K: 67\n",
      "V; 0\n",
      "K: 68\n",
      "V; 285\n",
      "K: 69\n",
      "V; 174\n",
      "K: 70\n",
      "V; 284\n",
      "K: 71\n",
      "V; 232\n",
      "K: 72\n",
      "V; 85\n",
      "K: 73\n",
      "V; 147\n",
      "K: 74\n",
      "V; 375\n",
      "K: 75\n",
      "V; 249\n",
      "K: 76\n",
      "V; 452\n",
      "K: 77\n",
      "V; 395\n",
      "K: 78\n",
      "V; 280\n",
      "K: 79\n",
      "V; 150\n",
      "K: 80\n",
      "V; 166\n",
      "K: 81\n",
      "V; 114\n",
      "K: 82\n",
      "V; 312\n",
      "K: 83\n",
      "V; 863\n",
      "K: 84\n",
      "V; 508\n",
      "K: 85\n",
      "V; 173\n",
      "K: 86\n",
      "V; 370\n",
      "K: 87\n",
      "V; 296\n",
      "K: 88\n",
      "V; 650\n",
      "K: 89\n",
      "V; 618\n",
      "K: 90\n",
      "V; 318\n",
      "K: 91\n",
      "V; 212\n",
      "K: 92\n",
      "V; 313\n",
      "K: 93\n",
      "V; 118\n",
      "K: 94\n",
      "V; 437\n",
      "K: 95\n",
      "V; 96\n",
      "K: 96\n",
      "V; 113\n",
      "K: 97\n",
      "V; 428\n",
      "K: 98\n",
      "V; 57\n",
      "K: 99\n",
      "V; 386\n",
      "K: 100\n",
      "V; 332\n",
      "K: 101\n",
      "V; 468\n",
      "K: 102\n",
      "V; 180\n",
      "K: 103\n",
      "V; 819\n",
      "K: 104\n",
      "V; 391\n",
      "K: 105\n",
      "V; 52\n",
      "K: 106\n",
      "V; 336\n",
      "K: 107\n",
      "V; 432\n",
      "K: 108\n",
      "V; 239\n",
      "K: 109\n",
      "V; 135\n",
      "K: 110\n",
      "V; 229\n",
      "K: 111\n",
      "V; 430\n",
      "K: 112\n",
      "V; 200\n",
      "K: 113\n",
      "V; 168\n",
      "K: 114\n",
      "V; 587\n",
      "K: 115\n",
      "V; 526\n",
      "K: 116\n",
      "V; 295\n",
      "K: 117\n",
      "V; 232\n",
      "K: 118\n",
      "V; 195\n",
      "K: 119\n",
      "V; 338\n",
      "K: 120\n",
      "V; 769\n",
      "K: 121\n",
      "V; 279\n",
      "K: 122\n",
      "V; 142\n",
      "K: 123\n",
      "V; 213\n",
      "K: 124\n",
      "V; 446\n",
      "K: 125\n",
      "V; 267\n",
      "K: 126\n",
      "V; 431\n",
      "K: 127\n",
      "V; 261\n",
      "K: 128\n",
      "V; 483\n",
      "K: 129\n",
      "V; 646\n",
      "K: 130\n",
      "V; 235\n",
      "K: 131\n",
      "V; 161\n",
      "K: 132\n",
      "V; 512\n",
      "K: 133\n",
      "V; 492\n",
      "K: 134\n",
      "V; 156\n",
      "K: 135\n",
      "V; 461\n",
      "K: 136\n",
      "V; 1246\n",
      "K: 137\n",
      "V; 782\n",
      "K: 138\n",
      "V; 604\n",
      "K: 139\n",
      "V; 525\n",
      "K: 140\n",
      "V; 287\n",
      "K: 141\n",
      "V; 330\n",
      "K: 142\n",
      "V; 229\n",
      "K: 143\n",
      "V; 319\n",
      "K: 144\n",
      "V; 218\n",
      "K: 145\n",
      "V; 180\n",
      "K: 146\n",
      "V; 119\n",
      "K: 147\n",
      "V; 266\n",
      "K: 148\n",
      "V; 418\n",
      "K: 149\n",
      "V; 277\n",
      "K: 150\n",
      "V; 261\n",
      "K: 151\n",
      "V; 585\n",
      "K: 152\n",
      "V; 336\n",
      "K: 153\n",
      "V; 525\n",
      "K: 154\n",
      "V; 248\n",
      "K: 155\n",
      "V; 232\n",
      "K: 156\n",
      "V; 885\n",
      "K: 157\n",
      "V; 490\n",
      "K: 158\n",
      "V; 317\n",
      "K: 159\n",
      "V; 302\n",
      "K: 160\n",
      "V; 368\n",
      "K: 161\n",
      "V; 544\n",
      "K: 162\n",
      "V; 363\n",
      "K: 163\n",
      "V; 558\n",
      "K: 164\n",
      "V; 160\n",
      "K: 165\n",
      "V; 318\n",
      "K: 166\n",
      "V; 267\n",
      "K: 167\n",
      "V; 209\n",
      "K: 168\n",
      "V; 96\n",
      "339.5325443786982\n"
     ]
    }
   ],
   "source": [
    "#punti medi per centroide\n",
    "sum = 0\n",
    "for k, v in points_centroids_map.items():\n",
    "    sum += len(v)\n",
    "    print(\"K:\", k)\n",
    "    print(\"V;\", len(v))\n",
    "\n",
    "mean = sum / 169\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parte per estrarre features immagine:\n",
    "import sys\n",
    "import torch\n",
    "import pretrainedmodels.utils as utils\n",
    "import pretrainedmodels\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "torch.set_printoptions(precision=20)\n",
    "\n",
    "model_name = 'alexnet'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "tf_img = utils.TransformImage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(image_name):\n",
    "    if image_name.startswith(\"http\"):\n",
    "        response = requests.get(image_name)\n",
    "        input_img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    else:\n",
    "        input_img = load_img(image_name)\n",
    "    input_tensor = tf_img(input_img)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    input = torch.autograd.Variable(input_tensor, requires_grad=False)\n",
    "    output_features = model.features(input).view(4096)\n",
    "    return output_features.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_vector(\"https://image.ibb.co/kYdbKT/IMG_20180725_194058_490.jpg\").reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "(1, 130)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test_pca = pca_model.transform(test_scaled)\n",
    "print(test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(point, points):\n",
    "    sP = points\n",
    "    pA = point\n",
    "    return np.linalg.norm(sP - pA, ord=2, axis=1.)  # 'distances' is a list\n",
    "\n",
    "#def get_closest_centroid2(array,centroids):\n",
    "    \n",
    "\n",
    "c = np.nanargmin(get_distances(test_pca, centroids))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8025629705307114\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(test_pca-centroids[31]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.973279913582314\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "print(distance.euclidean(test_pca, centroids[168]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexlist_to_points(lst,dataset):\n",
    "    points = np.empty([len(lst),dataset.shape[1]])\n",
    "    for index, val in enumerate(lst):\n",
    "        points[index] = dataset[val]\n",
    "    return points\n",
    "        \n",
    "\n",
    "cimg = indexlist_to_points(points_centroids_map[c],arr)      \n",
    "#dist_points = get_distances(test_pca, points_centroids_map[c] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerchiamo l'immagine più vicina tra quelle appartenenti al centroide!\n",
    "\n",
    "dist2 = get_distances(test_pca,cimg)\n",
    "d_c = np.argsort(dist2)\n",
    "smallest = d_c[:5]\n",
    "\n",
    "nearest_sample = []\n",
    "for s in smallest:\n",
    "    nearest_sample.append(points_centroids_map[c][np.asscalar(s)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "hashtags = []\n",
    "with open(\"/mnt/data/SCALABLE/HARRISON/pca/tag_list_clean.csv\", \"r\") as csvFile: \n",
    "    reader = csv.reader(csvFile,delimiter = \" \")\n",
    "    for row in reader:\n",
    "        hashtags.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arianagrande', 'selenagomez', 'mileycyrus', 'justinbieber']\n",
      "['orange', 'yellow', 'favorite']\n",
      "['boy', 'girl', 'sfs']\n",
      "['work', 'tired', 'goodnight']\n",
      "['boy', 'instachile']\n"
     ]
    }
   ],
   "source": [
    "for n in nearest_sample:\n",
    "    print(hashtags[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
