{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/data/SCALABLE/HARRISON/pca/pca_130_new.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leggo dataset e carico dati training\n",
    "arr = pd.read_csv(path, sep=\",\", header=None, index_col=None, dtype=\"float16\")\n",
    "arr = arr.to_numpy()\n",
    "\n",
    "points_centroids_map = pickle.load(open('points_centroids_map.pickle', 'rb'))\n",
    "centroids = pickle.load(open('centroids.pickle', 'rb'))\n",
    "assignments = pickle.load(open('assignments.pickle', 'rb'))\n",
    "\n",
    "pca_model = pickle.load(open('pca_model.pickle', 'rb'))\n",
    "scaler = pickle.load(open('scaler.pickle', 'rb'))\n",
    "\n",
    "hashtags = []\n",
    "with open(\"/mnt/data/SCALABLE/HARRISON/pca/tag_list_clean.csv\", \"r\") as csvFile: \n",
    "    reader = csv.reader(csvFile,delimiter = \" \")\n",
    "    for row in reader:\n",
    "        hashtags.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pretrainedmodels.utils as utils\n",
    "import pretrainedmodels\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "torch.set_printoptions(precision=20)\n",
    "\n",
    "model_name = 'alexnet'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "tf_img = utils.TransformImage(model)\n",
    "\n",
    "def get_vector(image_name):\n",
    "    if image_name.startswith(\"http\"):\n",
    "        response = requests.get(image_name)\n",
    "        input_img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    else:\n",
    "        input_img = load_img(image_name)\n",
    "    input_tensor = tf_img(input_img)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    input = torch.autograd.Variable(input_tensor, requires_grad=False)\n",
    "    output_features = model.features(input).view(4096)\n",
    "    return output_features.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(point, points):\n",
    "    sP = points\n",
    "    pA = point\n",
    "    return np.linalg.norm(sP - pA, ord=2, axis=1.)  # 'distances' is a list\n",
    "\n",
    "def indexlist_to_points(lst,dataset):\n",
    "    points = np.empty([len(lst),dataset.shape[1]])\n",
    "    for index, val in enumerate(lst):\n",
    "        points[index] = dataset[val]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"https://r.hswstatic.com/w_907/gif/tesla-cat.jpg\"\n",
    "k = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroid: 83\n",
      "[('bored', 4), ('black', 3), ('cat', 3), ('selfie', 3), ('blackandwhite', 3), ('eye', 2), ('mylove', 2), ('home', 2), ('sunday', 2), ('boy', 2), ('boyfriend', 2), ('love', 2), ('tired', 2), ('yellow', 1), ('truelove', 1), ('picoftheday', 1), ('photooftheday', 1), ('vegan', 1), ('sweet', 1), ('cute', 1), ('handsome', 1), ('awesome', 1), ('man', 1), ('amazing', 1), ('healthy', 1), ('russia', 1), ('selca', 1), ('afternoon', 1), ('photo', 1), ('today', 1), ('together', 1), ('lazy', 1), ('hand', 1), ('happiness', 1), ('couple', 1), ('catsofinstagram', 1), ('gay', 1), ('smile', 1), ('happy', 1), ('glass', 1), ('new', 1), ('tattoo', 1), ('friend', 1), ('girl', 1), ('moment', 1), ('night', 1), ('sad', 1), ('depressed', 1), ('depression', 1), ('live', 1), ('curlyhair', 1), ('sleep', 1)]\n"
     ]
    }
   ],
   "source": [
    "vector = get_vector(image_name).reshape(1,-1)\n",
    "sv = scaler.transform(vector)\n",
    "sample = pca_model.transform(sv)\n",
    "\n",
    "closest_centroid = np.nanargmin(get_distances(sample, centroids))\n",
    "print(\"centroid:\",closest_centroid)\n",
    "centroid_points = indexlist_to_points(points_centroids_map[closest_centroid], arr)\n",
    "\n",
    "nearest_k_images = np.argsort(get_distances(sample,centroid_points))[:k]\n",
    "\n",
    "nearest_samples = []\n",
    "for s in nearest_k_images:\n",
    "    nearest_samples.append(points_centroids_map[closest_centroid][np.asscalar(s)])\n",
    "    \n",
    "hash_dict = {}\n",
    "for n in nearest_samples:\n",
    "    for h in hashtags[n]:\n",
    "        if h in hash_dict:\n",
    "            hash_dict[h] = hash_dict[h] + 1\n",
    "        else:\n",
    "            hash_dict[h] = 1\n",
    "\n",
    "sorted_tags = sorted(hash_dict.items(), key=lambda kv: kv[1], reverse=True)            \n",
    "print(sorted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
