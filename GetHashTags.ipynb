{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/data/SCALABLE/HARRISON/pca/pca_130_new.csv\"\n",
    "tag_path = \"/mnt/data/SCALABLE/HARRISON/pca/tag_list_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leggo dataset e carico dati training\n",
    "arr = pd.read_csv(data_path, sep=\",\", header=None, index_col=None, dtype=\"float16\")\n",
    "arr = arr.to_numpy()\n",
    "\n",
    "points_centroids_map = pickle.load(open('points_centroids_map.pickle', 'rb'))\n",
    "centroids = pickle.load(open('centroids.pickle', 'rb'))\n",
    "assignments = pickle.load(open('assignments.pickle', 'rb'))\n",
    "\n",
    "pca_model = pickle.load(open('pca_model.pickle', 'rb'))\n",
    "scaler = pickle.load(open('scaler.pickle', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "hashtags = []\n",
    "with open(tag_path, \"r\") as csvFile: \n",
    "    reader = csv.reader(csvFile,delimiter = \" \")\n",
    "    for row in reader:\n",
    "        hashtags.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pretrainedmodels.utils as utils\n",
    "import pretrainedmodels\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "torch.set_printoptions(precision=20)\n",
    "\n",
    "model_name = 'alexnet'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "tf_img = utils.TransformImage(model)\n",
    "\n",
    "def get_vector(image_name):\n",
    "    if image_name.startswith(\"http\"):\n",
    "        response = requests.get(image_name)\n",
    "        input_img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    else:\n",
    "        input_img = load_img(image_name)\n",
    "    input_tensor = tf_img(input_img)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    input = torch.autograd.Variable(input_tensor, requires_grad=False)\n",
    "    output_features = model.features(input).view(4096)\n",
    "    return output_features.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(point, points):\n",
    "    sP = points\n",
    "    pA = point\n",
    "    return np.linalg.norm(sP - pA, ord=2, axis=1.)  # 'distances' is a list\n",
    "\n",
    "def indexlist_to_points(lst,dataset):\n",
    "    points = np.empty([len(lst),dataset.shape[1]])\n",
    "    for index, val in enumerate(lst):\n",
    "        points[index] = dataset[val]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"https://r.hswstatic.com/w_907/gif/tesla-cat.jpg\"\n",
    "k = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest centroid: 83\n",
      "cat 4\n",
      "bored 4\n",
      "black 3\n",
      "mylove 2\n",
      "home 2\n",
      "sunday 2\n",
      "love 2\n",
      "tired 2\n",
      "blackandwhite 2\n",
      "yellow 1\n",
      "eye 1\n",
      "truelove 1\n",
      "picoftheday 1\n",
      "photooftheday 1\n",
      "vegan 1\n",
      "sweet 1\n",
      "cute 1\n",
      "handsome 1\n",
      "awesome 1\n",
      "man 1\n",
      "amazing 1\n",
      "healthy 1\n",
      "russia 1\n",
      "catsofinstagram 1\n",
      "today 1\n",
      "together 1\n",
      "lazy 1\n",
      "boy 1\n",
      "hand 1\n",
      "boyfriend 1\n",
      "happiness 1\n",
      "couple 1\n",
      "afternoon 1\n",
      "funny 1\n",
      "omg 1\n",
      "loveyou 1\n",
      "wild 1\n",
      "fit 1\n",
      "fitness 1\n",
      "friend 1\n",
      "girl 1\n",
      "moment 1\n",
      "night 1\n",
      "curlyhair 1\n",
      "sleep 1\n",
      "gainpost 1\n",
      "selenagomez 1\n",
      "followtrain 1\n",
      "arianagrande 1\n",
      "justinbieber 1\n",
      "followforfollow 1\n",
      "selfie 1\n",
      "selca 1\n",
      "sad 1\n",
      "depressed 1\n",
      "depression 1\n",
      "live 1\n"
     ]
    }
   ],
   "source": [
    "vector = get_vector(image_name).reshape(1,-1)\n",
    "sv = scaler.transform(vector)\n",
    "sample = pca_model.transform(sv)\n",
    "\n",
    "closest_centroid = np.nanargmin(get_distances(sample, centroids))\n",
    "print(\"closest centroid:\",closest_centroid)\n",
    "centroid_points = indexlist_to_points(points_centroids_map[closest_centroid], arr)\n",
    "\n",
    "nearest_k_images = np.argsort(get_distances(sample,centroid_points))[:k]\n",
    "\n",
    "nearest_samples = []\n",
    "for s in nearest_k_images:\n",
    "    nearest_samples.append(points_centroids_map[closest_centroid][np.asscalar(s)])\n",
    "    \n",
    "hash_dict = {}\n",
    "for n in nearest_samples:\n",
    "    for h in hashtags[n]:\n",
    "        if h in hash_dict:\n",
    "            hash_dict[h] = hash_dict[h] + 1\n",
    "        else:\n",
    "            hash_dict[h] = 1\n",
    "\n",
    "sorted_tags = sorted(hash_dict.items(), key=lambda kv: kv[1], reverse=True)            \n",
    "for tag in sorted_tags:\n",
    "    print(tag[0] + \" \" + str(tag[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
